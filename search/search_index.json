{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":[" "],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Witaj w moim portfolio AI &amp; Data Science","text":"<p>Jestem pasjonatem danych, kt\u00f3ry skupia si\u0119 na przekszta\u0142caniu surowych informacji w konkretn\u0105 warto\u015b\u0107 biznesow\u0105. Znajdziesz tutaj dokumentacj\u0119 moich projekt\u00f3w \u2014 od kompleksowych analiz EDA, przez modele uczenia maszynowego (ML), a\u017c po nowoczesne aplikacje wykorzystuj\u0105ce du\u017ce modele j\u0119zykowe (LLM).</p> <p>Ka\u017cdy projekt to historia przej\u015bcia od surowego zbioru danych do dzia\u0142aj\u0105cego rozwi\u0105zania.</p>"},{"location":"#co-tutaj-znajdziesz","title":"Co tutaj znajdziesz?","text":"<ul> <li>Analizy Eksploracyjne (EDA): Odkrywanie wzorc\u00f3w i wizualizacja kluczowych trend\u00f3w w danych.</li> <li>Modele Machine Learning: Rozwi\u0105zania problem\u00f3w klasyfikacji, regresji oraz optymalizacji.</li> <li>Aplikacje LLM: Wykorzystanie potencja\u0142u sztucznej inteligencji w praktycznych narz\u0119dziach.</li> </ul>"},{"location":"#stack-technologiczny","title":"Stack Technologiczny","text":"<p>Moje projekty opieraj\u0105 si\u0119 na nowoczesnych narz\u0119dziach, kt\u00f3re wspieraj\u0105 ka\u017cdy etap pracy z danymi \u2014 od czyszczenia i wizualizacji, po wdra\u017canie zaawansowanych aplikacji AI.</p> <p>| Data Science &amp; Machine Learning | | :--- | :--- | | J\u0119zyki &amp; Biblioteki |  Python,  SQL, Pandas, Scikit-learn,  PyCaret | | Wizualizacja | Matplotlib, Seaborn,  Plotly | | Eksperymenty &amp; Tracking |  MLflow |</p> <p>| Generative AI &amp; LLMOps | | :--- | :--- | | Monitoring |  Langfuse | | Bazy Wektorowe |  Qdrant (RAG &amp; Vector Search) | | Interfejs AI |  Streamlit |</p> <p>| In\u017cynieria &amp; Narz\u0119dzia Pracy | | :--- | :--- | | Infrastruktura |  Digital Ocean | | Kontrola wersji |  Git | | \u015arodowisko | :simple-visualstudiocode: VS Code | | Zarz\u0105dzanie Projektami |  Trello |</p> <p>Zestawienie to odzwierciedla moje podej\u015bcie \"End-to-End\" \u2013 od surowego zapytania SQL, przez trenowanie modeli w MLflow, a\u017c po serwowanie gotowej aplikacji w chmurze.</p>"},{"location":"Community%20Matching%20App/","title":"Community Matching App","text":"<p>Otw\u00f3rz aplikacj\u0119 na Streamlit Cloud</p> <p>Aplikacja webowa stworzona w Streamlit, wykorzystuj\u0105ca model unsupervised learning (clustering) zbudowany w PyCaret do grupowania u\u017cytkownik\u00f3w na podstawie ich cech demograficznych i preferencji.</p> <p>Projekt prezentuje pe\u0142ny pipeline:</p> <ul> <li>przygotowanie danych  </li> <li>trenowanie modelu klasteryzacji  </li> <li>zapis modelu  </li> <li>inferencj\u0119 w aplikacji webowej  </li> <li>interpretacj\u0119 klastr\u00f3w  </li> <li>wizualizacj\u0119 wynik\u00f3w  </li> </ul>"},{"location":"Community%20Matching%20App/#cel-projektu","title":"Cel projektu","text":"<p>Celem aplikacji jest pogrupowanie u\u017cytkownik\u00f3w oraz przypisanie nowej osoby do najbardziej podobnej grupy na podstawie jej cech.</p> <p>U\u017cytkownik podaje dane:</p> <ul> <li>wiek</li> <li>poziomu wykszta\u0142cenia  </li> <li>ulubione zwierz\u0119</li> <li>preferowane miejsce sp\u0119dzania czasu  </li> <li>p\u0142e\u0107</li> </ul> <p>Na podstawie tych danych model przypisuje u\u017cytkownika do okre\u015blonego klastra, a aplikacja prezentuje charakterystyk\u0119 tej grupy.</p>"},{"location":"Community%20Matching%20App/#technologie","title":"Technologie","text":"Narz\u0119dzie Zastosowanie Python 3.11 J\u0119zyk programowania Streamlit Interfejs aplikacji webowej PyCaret (Clustering) Budowa i zapis pipeline ML Pandas Przetwarzanie danych Plotly Express Wizualizacje JSON Przechowywanie nazw i opis\u00f3w klastr\u00f3w CSV Dane wej\u015bciowe"},{"location":"Community%20Matching%20App/#architektura-aplikacji","title":"Architektura aplikacji","text":""},{"location":"Community%20Matching%20App/#1-adowanie-modelu","title":"1. \u0141adowanie modelu","text":"<p>Model klasteryzacji zapisany jako pipeline jest \u0142adowany przy starcie aplikacji:</p> <ul> <li><code>load_model(MODEL_NAME)</code> </li> <li>wykorzystanie <code>@st.cache_data</code> pozwala ograniczy\u0107 wielokrotne \u0142adowanie modelu oraz danych, poprawia wydajno\u015b\u0107 aplikacji</li> </ul>"},{"location":"Community%20Matching%20App/#2-wczytanie-danych-historycznych","title":"2. Wczytanie danych historycznych","text":"<p>Dane wszystkich uczestnik\u00f3w s\u0105 wczytywane z pliku CSV, a nast\u0119pnie przypisywane do klastr\u00f3w przy u\u017cyciu wytrenowanego modelu:</p> <ul> <li><code>pd.read_csv(DATA, sep=';')</code> </li> <li><code>predict_model(model, data=all_df)</code> </li> </ul> <p>Pozwala to analizowa\u0107 struktur\u0119 ca\u0142ej populacji w podziale na segmenty.</p>"},{"location":"Community%20Matching%20App/#3-predykcja-dla-nowego-uzytkownika","title":"3. Predykcja dla nowego u\u017cytkownika","text":"<p>Dane z formularza w panelu bocznym s\u0105 konwertowane do <code>DataFrame</code> i przekazywane do modelu:</p> <ul> <li><code>predict_model(model, data=person_df)</code> </li> </ul> <p>Model zwraca identyfikator klastra, do kt\u00f3rego u\u017cytkownik jest najbardziej podobny.</p>"},{"location":"Community%20Matching%20App/#4-interpretacja-klastra","title":"4. Interpretacja klastra","text":"<p>Ka\u017cdy klaster posiada:</p> <ul> <li>nazw\u0119  </li> <li>opis semantyczny  </li> </ul> <p>Informacje te s\u0105 przechowywane w pliku JSON i oddzielone od warstwy modelu, co zwi\u0119ksza czytelno\u015b\u0107 oraz umo\u017cliwia \u0142atw\u0105 modyfikacj\u0119 opis\u00f3w bez zmiany kodu aplikacji.</p>"},{"location":"Community%20Matching%20App/#wizualizacja-wynikow","title":"Wizualizacja wynik\u00f3w","text":"<p>Dla os\u00f3b nale\u017c\u0105cych do tego samego klastra generowane s\u0105 histogramy przedstawiaj\u0105ce:</p> <ul> <li>rozk\u0142ad wieku  </li> <li>rozk\u0142ad wykszta\u0142cenia  </li> <li>preferencje dotycz\u0105ce zwierz\u0105t  </li> <li>preferencje dotycz\u0105ce miejsca sp\u0119dzania czasu  </li> <li>rozk\u0142ad p\u0142ci  </li> </ul> <p>Wizualizacje tworzone s\u0105 przy u\u017cyciu <code>Plotly Express</code>, co umo\u017cliwia interaktywn\u0105 eksploracj\u0119 danych.</p>"},{"location":"Community%20Matching%20App/#mozliwe-rozszerzenia","title":"Mo\u017cliwe rozszerzenia","text":"<p>Projekt mo\u017cna rozbudowa\u0107 o:</p> <ul> <li>redukcj\u0119 wymiarowo\u015bci (PCA) w celu wizualizacji klastr\u00f3w w 2D  </li> <li>por\u00f3wnanie u\u017cytkownika z centroidem klastra  </li> <li>zapis nowych u\u017cytkownik\u00f3w do bazy danych  </li> <li>dynamiczne przetrenowanie modelu  </li> <li>panel administracyjny z analiz\u0105 segment\u00f3w  </li> <li>system rekomendacji oparty na klastrach  </li> </ul>"},{"location":"Community%20Matching%20App/#wartosc-biznesowa","title":"Warto\u015b\u0107 biznesowa","text":"<p>Rozwi\u0105zanie tego typu mo\u017ce by\u0107 wykorzystane w:</p> <ul> <li>segmentacji klient\u00f3w  </li> <li>marketingu personalizowanym  </li> <li>dopasowywaniu ofert  </li> <li>aplikacjach spo\u0142eczno\u015bciowych  </li> <li>systemach HR  </li> </ul>"},{"location":"Community%20Matching%20App/#podsumowanie","title":"Podsumowanie","text":"<p>Projekt \u0142\u0105czy:</p> <ul> <li>analiz\u0119 danych  </li> <li>machine learning  </li> <li>aplikacj\u0119 webow\u0105  </li> <li>wizualizacj\u0119  </li> <li>interpretacj\u0119 segment\u00f3w  </li> </ul> <p>Stanowi kompletny przyk\u0142ad wdro\u017cenia modelu klasteryzacji w \u015brodowisku aplikacji webowej (MVP), demonstruj\u0105c integracj\u0119 warstwy analitycznej z warstw\u0105 prezentacyjn\u0105.</p>"},{"location":"Half-Marathon%20Time%20Predictor/","title":"Half Marathon Predictor \u2013 End-to-End Machine Learning System","text":"<p>System uczenia maszynowego s\u0142u\u017c\u0105cy do predykcji czasu uko\u0144czenia P\u00f3\u0142maratonu Wroc\u0142awskiego na podstawie wynik\u00f3w biegu na 5 km, wieku oraz p\u0142ci. Projekt \u0142\u0105czy klasyczne modelowanie regresyjne z nowoczesnym podej\u015bciem Generative AI (LLM) do parsowania danych u\u017cytkownika.</p> <p></p> <p>Celem aplikacji by\u0142o nauczenie si\u0119 korzystania z us\u0142ug w chmurze (Digital Ocean) i monitorowaniem LLM (Langfuse).</p>"},{"location":"Half-Marathon%20Time%20Predictor/#architektura-systemu","title":"Architektura Systemu","text":"<p>Projekt zosta\u0142 zaprojektowany w oparciu o architektur\u0119 chmurow\u0105, zapewniaj\u0105c\u0105 separacj\u0119 danych, modelu i warstwy prezentacji:</p> <ul> <li>Cloud Data Lake: Wykorzystanie Digital Ocean Spaces (S3) do przechowywania surowych danych (CSV) oraz sk\u0142adowania wyeksportowanych artefakt\u00f3w modeli (<code>.pkl</code>).</li> <li>ML Pipeline: Zautomatyzowany proces przetwarzania danych i trenowania modeli przy u\u017cyciu PyCaret w Python 3.11.</li> <li>App Layer: Interaktywna aplikacja webowa zbudowana w Streamlit.</li> <li>AI/NLP Layer: Integracja z OpenAI API (GPT) w celu umo\u017cliwienia u\u017cytkownikom wprowadzania danych w formie tekstu naturalnego.</li> <li>Observability: Pe\u0142ny monitoring zapyta\u0144 i koszt\u00f3w LLM za pomoc\u0105 Langfuse.</li> <li>Deployment: Aplikacja wdro\u017cona na Digital Ocean App Platform.</li> </ul>"},{"location":"Half-Marathon%20Time%20Predictor/#stack-technologiczny","title":"Stack Technologiczny","text":"Kategoria Technologie J\u0119zyk Python 3.11 Data Science Pandas, NumPy, PyCaret Cloud &amp; DevOps Digital Ocean Spaces, Digital Ocean App Platform, Boto3 Generative AI OpenAI API (GPT-4o-mini) Monitoring Langfuse Frontend Streamlit"},{"location":"Half-Marathon%20Time%20Predictor/#cykl-zycia-projektu","title":"Cykl \u017bycia Projektu","text":""},{"location":"Half-Marathon%20Time%20Predictor/#1-inzynieria-danych-etl","title":"1. In\u017cynieria Danych (ETL)","text":"<ul> <li>Pozyskiwanie: Synchronizacja lokalnych zbior\u00f3w danych z chmur\u0105 Digital Ocean za pomoc\u0105 skrypt\u00f3w opartych na <code>boto3</code>.</li> <li>Czyszczenie: Agregacja wynik\u00f3w z r\u00f3\u017cnych edycji P\u00f3\u0142maratonu Wroc\u0142awskiego (2023-2024), ujednolicenie jednostek czasu (konwersja na sekundy) oraz filtracja b\u0142\u0119dnych rekord\u00f3w.</li> </ul>"},{"location":"Half-Marathon%20Time%20Predictor/#2-modelowanie-automl","title":"2. Modelowanie (AutoML)","text":"<p>Wykorzysta\u0142em bibliotek\u0119 PyCaret do przeprowadzenia eksperyment\u00f3w: * Por\u00f3wnanie kilkunastu algorytm\u00f3w regresyjnych (m.in. Linear Regression, Random Forest, LightGBM). * Finalizacja modelu Gradient Boosting Regressor, kt\u00f3ry wykaza\u0142 najlepszy stosunek precyzji do zdolno\u015bci generalizacji. * Zapisanie modelu jako artefakt bezpo\u015brednio do chmury S3.</p>"},{"location":"Half-Marathon%20Time%20Predictor/#3-interfejs-uzytkownika-i-ai","title":"3. Interfejs U\u017cytkownika i AI","text":"<p>Kluczow\u0105 cech\u0105 aplikacji jest Natural Language Input. U\u017cytkownik nie musi wype\u0142nia\u0107 sztywnego formularza. Mo\u017ce napisa\u0107:</p> <p>\"Mam 28 lat, jestem m\u0119\u017cczyzn\u0105 i biegam 5km w 24 minuty i 15 sekund.\"</p> <p>Model LLM (OpenAI) ekstrahuje z tego zdania parametry:  <pre><code>{\n\"age\": 28,\n\"gender\": \"m\u0119\u017cczyzna\",\n\"time_5km\": 1455\n}\n</code></pre> kt\u00f3re nast\u0119pnie zasilaj\u0105 model ML.</p>"},{"location":"Half-Marathon%20Time%20Predictor/#4-monitoring-i-bezpieczenstwo","title":"4. Monitoring i Bezpiecze\u0144stwo","text":"<p>Dzi\u0119ki integracji Langfuse, ka\u017cda pr\u00f3ba predykcji jest monitorowana pod k\u0105tem: * Poprawno\u015bci parsowania danych przez LLM. * Czasu odpowiedzi (latency) i zu\u017cycia token\u00f3w (koszt\u00f3w). * Historii zapyta\u0144, co pozwala na ci\u0105g\u0142e doskonalenie prompt\u00f3w systemowych.</p> <p>Aplikacja jest w pe\u0142ni skonteneryzowana i zoptymalizowana pod Digital Ocean App Platform.</p> <p>Ze wzgl\u0119du na koszty utrzymania aplikacji zosta\u0142a usuni\u0119ta z <code>Digital Ocean</code>.</p> <p>Repozytorium GitHub</p>"},{"location":"iris/","title":"Analiza danych zbioru Irys\u00f3w","text":""},{"location":"iris/#o-danych","title":"O Danych","text":"<p>Zbi\u00f3r danych zawiera informacje o trzech gatunkach irys\u00f3w: Iris setosa, Iris versicolor, i Iris virginica.</p> <p>Dane obejmuj\u0105 pomiary czterech cech: d\u0142ugo\u015b\u0107 i szeroko\u015b\u0107 dzia\u0142ki kielicha oraz d\u0142ugo\u015b\u0107 i szeroko\u015b\u0107 p\u0142atka.</p> <p>Ka\u017cdy wiersz w zbiorze danych reprezentuje pojedynczy kwiat, a warto\u015bci pomiar\u00f3w s\u0105 podane w centymetrach.</p> <p>Zbi\u00f3r sk\u0142ada si\u0119 z 150 pr\u00f3bek, po 50 dla ka\u017cdego gatunku.</p> <p>Kolumny:</p> <ul> <li>d\u0142ugo\u015b\u0107\u00a0kielicha (sepal length) - D\u0142ugo\u015b\u0107 kielicha w cm</li> <li>szeroko\u015b\u0107 kielicha (sepal width) - Szeroko\u015b\u0107 kielicha w cm</li> <li>d\u0142ugo\u015b\u0107 p\u0142atka (petal length) - D\u0142ugo\u015b\u0107 p\u0142atka w cm</li> <li>szeroko\u015b\u0107 p\u0142atka (petal width) - Szeroko\u015b\u0107 p\u0142atka w cm</li> <li>klasa (class) - Klasa irysa (setosa, versicolor, virginica)</li> </ul> <p></p> <p>Pobierz Notebook</p>"},{"location":"iris/#analiza-eda","title":"Analiza EDA","text":""},{"location":"obecny/","title":"LYRA \u2013 Learning Your Relevant Attributes","text":"<p>Aplikacja do automatycznej detekcji typu problemu ML (klasyfikacja/regresja), budowania modeli i identyfikacji najwa\u017cniejszych cech wp\u0142ywaj\u0105cych na wynik.</p> <p>Otw\u00f3rz aplikacj\u0119 na Streamlit Cloud</p>"},{"location":"obecny/#cel-aplikacji","title":"Cel aplikacji","text":"<p>LYRA umo\u017cliwia:</p> <ul> <li>Automatyczne wykrywanie typu problemu (klasyfikacja vs regresja)</li> <li>Budowanie najlepszego modelu predykcyjnego</li> <li>Identyfikacj\u0119 najwa\u017cniejszych cech wp\u0142ywaj\u0105cych na wynik</li> <li>Wizualizacj\u0119 Feature Importance</li> </ul>"},{"location":"obecny/#funkcjonalnosci","title":"Funkcjonalno\u015bci","text":""},{"location":"obecny/#wielozrodowe-wczytywanie-danych","title":"Wielo\u017ar\u00f3d\u0142owe wczytywanie danych","text":"<ul> <li>Pliki lokalne z folderu <code>data/</code></li> <li>Predefiniowane zbiory PyCaret (blood, heart, questions, spx, automobile, energy)</li> <li>Upload w\u0142asnych plik\u00f3w (CSV, XLSX, XLS, JSON)</li> </ul>"},{"location":"obecny/#inteligentna-detekcja-problemu","title":"Inteligentna detekcja problemu","text":"<p>Automatyczne rozpoznawanie typu problemu na podstawie: - Typu danych kolumny docelowej - Liczby unikalnych warto\u015bci - Logiki: dane nienumeryczne \u2192 klasyfikacja; numeryczne z \u226420 warto\u015bciami \u2192 klasyfikacja; pozosta\u0142e \u2192 regresja</p>"},{"location":"obecny/#walidacja-i-czyszczenie-danych","title":"Walidacja i czyszczenie danych","text":"<ul> <li>Automatyczne usuwanie wierszy z brakami w kolumnie docelowej</li> <li>Wykrywanie klas z niewystarczaj\u0105c\u0105 liczb\u0105 pr\u00f3bek</li> <li>Szczeg\u00f3\u0142owe komunikaty o statusie danych</li> </ul>"},{"location":"obecny/#porownanie-modeli-ml","title":"Por\u00f3wnanie modeli ML","text":"<p>Aplikacja testuje i wybiera najlepszy model z dost\u0119pnych algorytm\u00f3w:</p> <p>Klasyfikacja: LightGBM, Random Forest, Logistic Regression</p> <p>Regresja: LightGBM, Random Forest, Linear Regression</p> <p>Uwaga: Modele zosta\u0142y dobrane pod k\u0105tem gwarantowanej obs\u0142ugi Feature Importance (<code>feature_importances_</code> lub <code>coef_</code>) oraz optymalnej szybko\u015bci oblicze\u0144.</p>"},{"location":"obecny/#wizualizacja-i-analiza","title":"Wizualizacja i analiza","text":"<ul> <li>Wykres Feature Importance (automatycznie generowany)</li> <li>Identyfikacja najwa\u017cniejszej cechy z warto\u015bci\u0105 wagi</li> <li>Szczeg\u00f3\u0142owy opis interpretacji wykresu</li> </ul>"},{"location":"obecny/#technologie","title":"Technologie","text":"Narz\u0119dzie Zastosowanie J\u0119zyk Python 3.11 Streamlit Interfejs webowy PyCaret AutoML i por\u00f3wnywanie modeli Pandas Przetwarzanie danych Pillow Wy\u015bwietlanie wykres\u00f3w"},{"location":"obecny/#requirementstxt","title":"Requirements.txt","text":"<pre><code>streamlit\npandas\npycaret\npillow\nnumpy\nopenpyxl\n</code></pre>"},{"location":"obecny/#jak-uzywac","title":"Jak u\u017cywa\u0107","text":"<ol> <li>Wybierz \u017ar\u00f3d\u0142o danych \u2013 lokalny plik, PyCaret dataset lub upload w\u0142asny</li> <li>Wczytaj dane \u2013 aplikacja wy\u015bwietli podgl\u0105d i statystyki</li> <li>Wybierz kolumn\u0119 docelow\u0105 \u2013 automatyczna detekcja typu problemu</li> <li>Wykryj cechy \u2013 kliknij przycisk \"\ud83d\udd0d Wykryj najwa\u017cniejsze cechy\"</li> <li>Analiza wynik\u00f3w \u2013 zobacz wykres Feature Importance i najwa\u017cniejsz\u0105 cech\u0119</li> </ol>"},{"location":"obecny/#struktura-projektu","title":"Struktura projektu","text":"<pre><code>lyra/\n\u251c\u2500\u2500 app.py                 # G\u0142\u00f3wna aplikacja Streamlit\n\u251c\u2500\u2500 data/                  # Folder na lokalne pliki danych\n\u2502   \u2514\u2500\u2500 titanic.csv        # Przyk\u0142adowy zbi\u00f3r testowy\n\u2502   \u2514\u2500\u2500 iris.csv           # Przyk\u0142adowy zbi\u00f3r testowy\n\u251c\u2500\u2500 plots_feature/         # Automatycznie generowane wykresy\n\u251c\u2500\u2500 requirements.txt       # Zale\u017cno\u015bci Python\n\u2514\u2500\u2500 README.md              # Dokumentacja\n</code></pre>"},{"location":"obecny/#konfiguracja","title":"Konfiguracja","text":""},{"location":"obecny/#optymalizacja-wydajnosci","title":"Optymalizacja wydajno\u015bci","text":"<ul> <li>Cross-validation zredukowane do 2 fold\u00f3w (domy\u015blnie 10) dla szybszych oblicze\u0144</li> <li>Lista modeli ograniczona do najstabilniejszych algorytm\u00f3w</li> </ul>"},{"location":"obecny/#minimalne-wymagania-danych","title":"Minimalne wymagania danych","text":"<ul> <li>Minimum 10 wierszy po usuni\u0119ciu brak\u00f3w w kolumnie docelowej</li> <li>Dla klasyfikacji: ka\u017cda klasa musi mie\u0107 \u22652 pr\u00f3bki</li> </ul>"},{"location":"obecny/#znane-ograniczenia","title":"Znane ograniczenia","text":"<ul> <li>Modele bez <code>feature_importances_</code> lub <code>coef_</code> nie s\u0105 obs\u0142ugiwane (np. KNN, Naive Bayes, niekt\u00f3re SVM)</li> <li>D\u0142ugie obliczenia na du\u017cych zbiorach danych (&gt;1000 wierszy) mog\u0105 przekracza\u0107 limity Streamlit Cloud</li> <li>Brak obs\u0142ugi danych tekstowych (NLP) \u2013 wymagane jest preprocessowanie</li> </ul>"},{"location":"obecny/#roadmap-plan-rozwoju","title":"Roadmap (plan rozwoju)","text":"<ul> <li>SHAP values dla g\u0142\u0119bszej interpretacji modeli</li> <li>Automatyczny wyb\u00f3r kolumny docelowej</li> <li>Interaktywne wykresy Plotly</li> <li>Eksport raport\u00f3w do PDF/HTML</li> <li>Obs\u0142uga wi\u0119kszej liczby modeli (po optymalizacji)</li> <li>Preprocessowanie danych (imputacja, encoding)</li> </ul>"},{"location":"titanic/","title":"Analiza danych zbioru Titanic","text":""},{"location":"titanic/#o-danych","title":"O Danych","text":"<p>Zbi\u00f3r danych zawiera informacje o pasa\u017cerach RMS Titanic, kt\u00f3ry zaton\u0105\u0142 15 kwietnia 1912 roku po zderzeniu z g\u00f3r\u0105 lodow\u0105. Dane obejmuj\u0105 takie atrybuty jak klasa podr\u00f3\u017cy, wiek, p\u0142e\u0107, liczba rodze\u0144stwa/ma\u0142\u017conk\u00f3w na pok\u0142adzie, liczba rodzic\u00f3w/dzieci na pok\u0142adzie, cena biletu oraz miejsce zaokr\u0119towania.</p> <p>Zbi\u00f3r zawiera tak\u017ce informacj\u0119 o tym, czy pasa\u017cer prze\u017cy\u0142 katastrof\u0119.</p> <p>Titanic przewozi\u0142 ponad 2,200 os\u00f3b, z czego ponad 1,500 zgin\u0119\u0142o, co czyni t\u0119 katastrof\u0119 jedn\u0105 z najbardziej tragicznych w historii morskiej.</p> <p>Kolumny:</p> <ul> <li>pclass - Klasa biletu</li> <li>survived - Czy pasa\u017cer prze\u017cy\u0142 katastrof\u0119</li> <li>name - Imi\u0119 i nazwisko pasa\u017cera</li> <li>sex - P\u0142e\u0107 pasa\u017cera</li> <li>age - Wiek pasa\u017cera</li> <li>sibsp - Liczba rodze\u0144stwa/ma\u0142\u017conk\u00f3w na pok\u0142adzie</li> <li>parch - Liczba rodzic\u00f3w/dzieci na pok\u0142adzie</li> <li>ticket - Numer biletu</li> <li>fare - Cena biletu</li> <li>cabin - Numer kabiny</li> <li>embarked - Port, w kt\u00f3rym pasa\u017cer wszed\u0142 na pok\u0142ad (C = Cherbourg, Q = Queenstown, S = Southampton)</li> <li>boat - Numer \u0142odzi ratunkowej</li> <li>body - Numer cia\u0142a (je\u015bli pasa\u017cer nie prze\u017cy\u0142 i cia\u0142o zosta\u0142o odnalezione)</li> <li>home.dest - Miejsce docelowe</li> </ul> <p>Pobierz Notebook</p>"},{"location":"titanic/#analiza-eda","title":"Analiza EDA","text":""}]}